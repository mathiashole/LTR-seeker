randomPoiss = rpois(sec1000en100[i],16.5)
poissLGN[i] = mean(randomPoiss)
}
#Se crea un Datafarme para darle los datos a ggplot
poissXn <- c(15.86000, 15.79500, 16.37333, 16.49750, 16.23800, 16.52000, 16.69571, 16.51000, 16.57444, 16.31300)
NXntotal <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
Dfpoiss <- data.frame(poissXn = poissXn, NXntotal = NXntotal)
mean_poiss <- mean(poissXn)
library(ggplot2)
gppoissLGN = ggplot(Dfpoiss, aes(x=NXntotal, y=poissXn, color="black", size="black"))+
geom_point()+
theme(legend.position = "none", panel.background = element_rect(fill = "white", colour =  "grey50"))+
library(ggExtra)
ggMarginal(gppoissLGN, type = "density", fill = "#69b3a2", color="#e9ecef", alpha=0.8)
gppoissLGN = ggplot(Dfpoiss, aes(x=NXntotal, y=poissXn, color="black", size="black"))+
geom_point()+
theme(legend.position = "none", panel.background = element_rect(fill = "white", colour =  "grey50"))
library(ggExtra)
ggMarginal(gppoissLGN, type = "density", fill = "#69b3a2", color="#e9ecef", alpha=0.8)
gppoissLGN = ggplot(Dfpoiss, aes(x=NXntotal, y=poissXn, color="black", size="black"))+
geom_point()+
theme(legend.position = "none", panel.background = element_rect(fill = "white", colour =  "grey50"))+
geom_hline(yintercept = 16.5)
library(ggExtra)
ggMarginal(gppoissLGN, type = "density", fill = "#69b3a2", color="#e9ecef", alpha=0.8)
gppoissLGN = ggplot(Dfpoiss, aes(x=NXntotal, y=poissXn, color="black", size="black"))+
geom_point()+
theme(legend.position = "none", panel.background = element_rect(fill = "white", colour =  "grey50"))+
geom_hline(yintercept = 16.5, colour = "#69b3a2")
library(ggExtra)
ggMarginal(gppoissLGN, type = "density", fill = "#69b3a2", color="#e9ecef", alpha=0.8)
gppoissLGN = ggplot(Dfpoiss, aes(x=NXntotal, y=poissXn, color="black", size="black"))+
geom_point()+
theme(legend.position = "none", panel.background = element_rect(fill = "white", colour =  "grey50"))+
geom_hline(yintercept = 16.5, colour = "#69b3a2", size = 10)
library(ggExtra)
ggMarginal(gppoissLGN, type = "density", fill = "#69b3a2", color="#e9ecef", alpha=0.8)
gppoissLGN = ggplot(Dfpoiss, aes(x=NXntotal, y=poissXn, color="black", size="black"))+
geom_point()+
theme(legend.position = "none", panel.background = element_rect(fill = "white", colour =  "grey50"))+
geom_hline(yintercept = 16.5, colour = "#69b3a2", size = 3)
library(ggExtra)
ggMarginal(gppoissLGN, type = "density", fill = "#69b3a2", color="#e9ecef", alpha=0.8)
gppoissLGN = ggplot(Dfpoiss, aes(x=NXntotal, y=poissXn, color="black", size="black"))+
geom_point()+
theme(legend.position = "none", panel.background = element_rect(fill = "white", colour =  "grey50"))+
geom_hline(yintercept = 16.5, colour = "#69b3a2", size = 2)
library(ggExtra)
ggMarginal(gppoissLGN, type = "density", fill = "#69b3a2", color="#e9ecef", alpha=0.8)
gppoissLGN = ggplot(Dfpoiss, aes(x=NXntotal, y=poissXn, color="black", size="black"))+
geom_point()+
theme(legend.position = "none", panel.background = element_rect(fill = "white", colour =  "grey50"))+
geom_hline(yintercept = 16.5, colour = "#69b3a2", size = 1)
library(ggExtra)
ggMarginal(gppoissLGN, type = "density", fill = "#69b3a2", color="#e9ecef", alpha=0.8)
#Se define un vector en secuencia de 100 en 100 hasta 1000
sec1000en100 = seq(100,1000,100)
VarianzaPoiss = rep(0,10)
#Bucle for para aplicar Ley de los Grandes N y calcular Varianza
for(i in 1:10){
randomPoiss = rpois(sec1000en100[i],16.5)
VarianzaPoiss[i] = (sd(x)^2)
poissLGN[i] = mean(randomPoiss)
}
#Bucle for para aplicar Ley de los Grandes N y calcular Varianza
for(i in 1:10){
randomPoiss = rpois(sec1000en100[i],16.5)
VarianzaPoiss[i] = (sd(randomPoiss)^2)
poissLGN[i] = mean(randomPoiss)
}
VarianzaPoiss
#Se crea un Datafarme para darle los datos a ggplot de la Varianza
varianzaPss <- c(19.41051, 14.53266, 15.94759, 14.67466, 16.75253, 16.27222, 15.89483, 15.69960, 16.60458, 16.01401)
nVarianza <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
DfVarianzaPss <- data.frame(varianzaPss = varianzaPss, nVarianza = nVarianza)
library(ggplot2)
ggVarianzaPoiss = ggplot(DfVarianzaPss, aes(x=nVarianza, y=varianzaPss, color="black", size="black"))+
geom_point()+
theme(legend.position = "none", panel.background = element_rect(fill = "white", colour =  "grey50"))
library(ggExtra)
ggMarginal(, type = "density", fill = "#69b3a2", color="#e9ecef", alpha=0.8)
ggVarianzaPoiss
library(ggExtra)
ggMarginal(, type = "density", fill = "#69b3a2", color="#e9ecef", alpha=0.8)
ggMarginal(ggVarianzaPoiss, type = "density", fill = "#69b3a2", color="#e9ecef", alpha=0.8)
ggVarianzaPoiss = ggplot(DfVarianzaPss, aes(x=nVarianza, y=varianzaPss, color="black", size="black"))+
geom_point()+
theme(legend.position = "none", panel.background = element_rect(fill = "white", colour =  "grey50"))+
geom_hline(yintercept = 16.5, colour = "#69b3a2", size = 1)
ggMarginal(ggVarianzaPoiss, type = "density", fill = "#69b3a2", color="#e9ecef", alpha=0.8)
ggVarianzaPoiss = ggplot(DfVarianzaPss, aes(x=nVarianza, y=varianzaPss, color="black", size="black"))+
geom_point()+
theme(legend.position = "none", panel.background = element_rect(fill = "white", colour =  "grey50"))+
geom_hline(yintercept = 16.33, colour = "#69b3a2", size = 1)
library(ggExtra)
ggMarginal(ggVarianzaPoiss, type = "density", fill = "#69b3a2", color="#e9ecef", alpha=0.8)
ggVarianzaPoiss = ggplot(DfVarianzaPss, aes(x=nVarianza, y=varianzaPss, color="black", size="black"))+
geom_point()+
theme(legend.position = "none", panel.background = element_rect(fill = "white", colour =  "grey50"))+
geom_hline(yintercept = 16.5, colour = "#69b3a2", size = 1)
library(ggExtra)
ggMarginal(ggVarianzaPoiss, type = "density", fill = "#69b3a2", color="#e9ecef", alpha=0.8)
View(Dfpoiss)
View(Dfpoiss)
install.packages("BiocManager")
BiocManager::available()
BiocManager::install()
library(BiocManager)
clear
lss
les
less
library(BiocManager)
matrix(runif(25,1,100), ncol = 5)
matrix(runif(20,1,100), ncol = 5)
matrix(runif(25,1,100), nrow = 5)
matrix(runif(25,1,100))
runif(25,1,100)
x[5,]
x <-runif(25,1,100)
x[5,]
x[,5]
x[5]
x[length(5)]
View(DfVarianzaPss)
DfVarianzaPss[1:2]
DfVarianzaPss[,c(1,2)]
DfVarianzaPss[,1:2]
DfVarianzaPss$peso$altura
install.packages("BiocManager")
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("Biobase")
y
ls
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install(version = "3.14")
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install(version = "3.14")
BiocManager::install("Biostrings")
library(Biobase)
BiocManager::install("Biostrings")
Biostrings
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("Biostrings")
library("Biostrings")
install.packages("wordcloud2")
inscripciones <- c(330, 589, 967, 750, 2366, 634)
facultades <- c("Agronomía","Veterinaria","Arquitectura, Diseño y Urbanismo","Ciencias ","Ingeniería","Química")
inscripciones <- c(330, 589, 967, 750, 2366, 634)
dataf <- data.frame(facultades, inscripciones)
library(wordcloud2)
wordcloud2(data = dataf, size=1.6)
wordcloud2(data = dataf)
facultades <- c("Agronomía","Veterinaria","Arquitectura","Ciencias ","Ingeniería","Química")
inscripciones <- c(330, 589, 967, 750, 2366, 634)
dataf
wordcloud2(data = dataf)
facultades <- c("Agronomía","Veterinaria","Arquitectura","Ciencias ","Ingenieria","Quimica")
inscripciones <- c(330, 589, 967, 750, 2366, 634)
dataf <- data.frame(facultades, inscripciones)
library(wordcloud2)
wordcloud2(data = dataf)
wordcloud2(data = dataf, size=1.6, color='random-dark')
wordcloud2(data = dataf, size=1.6, color='random-light', backgroundColor="black")
wordcloud2(data = dataf, size=5, color='random-light', backgroundColor="black")
wordcloud2(data = dataf, size=1, color='random-light', backgroundColor="black")
wordcloud2(data = dataf, size=0.3, color='random-light', backgroundColor="black")
wordcloud2(data = dataf, size=0.4, color='random-light', backgroundColor="black")
wordcloud2(data = dataf, size=0.9, color='random-light', backgroundColor="black")
wordcloud2(data = dataf, size=0.8, color='random-light', backgroundColor="black")
wordcloud2(data = dataf, size=0.7, color='random-light', backgroundColor="black")
wordcloud2(data = dataf, size=0.6, color='random-light', backgroundColor="black")
wordcloud2(data = dataf, size=0.5, color='random-light', backgroundColor="black")
wordcloud2(data = dataf, size=0.5, color='random-light', backgroundColor="black")
wordcloud2(data = dataf, size=0.5, color='random-light', backgroundColor="black")
wordcloud2(data = dataf, size=0.5, color='random-light', backgroundColor="black")
wordcloud2(data = dataf, size=0.5, color='random-light', backgroundColor="black")
wordcloud2(data = dataf, size=0.5, color='random-light', backgroundColor="black")
wordcloud2(data = dataf, size=0.5, color='random-light', backgroundColor="black")
wordcloud2(data = dataf, size=0.5, color='random-light', backgroundColor="black")
wordcloud2(data = dataf, size=0.5, color='random-light', backgroundColor="black")
facultades <- c("Agronomía","Veterinaria","Arquitectura","Ciencias ","Ingenieria","Quimica")
inscripciones <- c(330, 589, 967, 750, 2366, 634)
dataf <- data.frame(facultades, inscripciones)
library(wordcloud2)
wordcloud2(data = dataf, size=0.5, color='random-light', backgroundColor="black")
wordcloud2(data = dataf, size=0.5, color='random-light', backgroundColor="black")
facultades <- c("Agronomía","Veterinaria","Arquitectura","Ciencias ","Ingenieria","Quimica")
inscripciones <- c(330, 589, 967, 750, 2366, 634)
dataf <- data.frame(facultades, inscripciones)
library(wordcloud2)
wordcloud2(data = dataf, size=0.5, color='random-light', backgroundColor="black")
install.packages("reshape")
install.packages("tm")
# -- STEP 1 : GET THE DATA
# A dataset with 5485 lines, each line has several words.
dataset=read.delim("https://raw.githubusercontent.com/TATABOX42/text-mining-in-r/master/dataset.txt", header=FALSE)
View(dataset)
# The labels of each line of the dataset file
dataset_labels <- read.delim("https://raw.githubusercontent.com/TATABOX42/text-mining-in-r/master/labels.txt",header=FALSE)
View(dataset_labels)
dataset_labels <- dataset_labels[,1]
dataset_labels <- dataset_labels[,1]
# The labels of each line of the dataset file
dataset_labels <- read.delim("https://raw.githubusercontent.com/TATABOX42/text-mining-in-r/master/labels.txt",header=FALSE)
dataset_labels <- dataset_labels[,1]
dataset_labels_p <- paste("class",dataset_labels,sep="_")
View(dataset)
unique_labels <- unique(dataset_labels_p)
# merge documents that match certain class into a list object
dataset_s <- sapply(unique_labels,function(label) list( dataset[dataset_labels_p %in% label,1] ) )
View(dataset_s)
# -- STEP2 : COMPUTE DOCUMENT CORPUS TO MAKE TEXT MINING
# convert each list content into a corpus
dataset_corpus <- lapply(dataset_s, function(x) Corpus(VectorSource( toString(x) )))
# merge documents that match certain class into a list object
dataset_s <- sapply(unique_labels,function(label) list( dataset[dataset_labels_p %in% label,1] ) )
# -- STEP2 : COMPUTE DOCUMENT CORPUS TO MAKE TEXT MINING
# convert each list content into a corpus
dataset_corpus <- lapply(dataset_s, function(x) Corpus(VectorSource( toString(x) )))
# merge all documents into one single corpus
dataset_corpus_all <- dataset_corpus[[1]]
for (i in 2:length(unique_labels)) { dataset_corpus_all <- c(dataset_corpus_all,dataset_corpus[[i]]) }
# remove punctuation, numbers and stopwords
dataset_corpus_all <- tm_map(dataset_corpus_all, removePunctuation)
dataset_corpus_all <- tm_map(dataset_corpus_all, removeNumbers)
dataset_corpus_all <- tm_map(dataset_corpus_all, function(x) removeWords(x,stopwords("english")))
#remove some unintersting words
words_to_remove <- c("said","from","what","told","over","more","other","have","last","with","this","that","such","when","been","says","will","also","where","why","would","today")
dataset_corpus_all <- tm_map(dataset_corpus_all, removeWords, words_to_remove)
# compute term matrix & convert to matrix class --> you get a table summarizing the occurence of each word in each class.
document_tm <- TermDocumentMatrix(dataset_corpus_all)
document_tm_mat <- as.matrix(document_tm)
colnames(document_tm_mat) <- unique_labels
document_tm_clean <- removeSparseTerms(document_tm, 0.8)
document_tm_clean_mat <- as.matrix(document_tm_clean)
colnames(document_tm_clean_mat) <- unique_labels
# remove words in term matrix with length < 4
index <- as.logical(sapply(rownames(document_tm_clean_mat), function(x) (nchar(x)>3) ))
document_tm_clean_mat_s <- document_tm_clean_mat[index,]
# Have a look to the matrix you are going to use for wordcloud !
head(document_tm_clean_mat_s)
# merge all documents into one single corpus
dataset_corpus_all <- dataset_corpus[[1]]
library(reshape)
library(tm)
library(wordcloud)
# -- STEP 1 : GET THE DATA
# A dataset with 5485 lines, each line has several words.
dataset=read.delim("https://raw.githubusercontent.com/TATABOX42/text-mining-in-r/master/dataset.txt", header=FALSE)
# The labels of each line of the dataset file
dataset_labels <- read.delim("https://raw.githubusercontent.com/TATABOX42/text-mining-in-r/master/labels.txt",header=FALSE)
dataset_labels <- dataset_labels[,1]
dataset_labels_p <- paste("class",dataset_labels,sep="_")
unique_labels <- unique(dataset_labels_p)
# merge documents that match certain class into a list object
dataset_s <- sapply(unique_labels,function(label) list( dataset[dataset_labels_p %in% label,1] ) )
# -- STEP2 : COMPUTE DOCUMENT CORPUS TO MAKE TEXT MINING
# convert each list content into a corpus
dataset_corpus <- lapply(dataset_s, function(x) Corpus(VectorSource( toString(x) )))
# merge all documents into one single corpus
dataset_corpus_all <- dataset_corpus[[1]]
for (i in 2:length(unique_labels)) { dataset_corpus_all <- c(dataset_corpus_all,dataset_corpus[[i]]) }
# remove punctuation, numbers and stopwords
dataset_corpus_all <- tm_map(dataset_corpus_all, removePunctuation)
# remove punctuation, numbers and stopwords
dataset_corpus_all <- tm_map(dataset_corpus_all, removePunctuation)
dataset_corpus_all <- tm_map(dataset_corpus_all, removeNumbers)
dataset_corpus_all <- tm_map(dataset_corpus_all, function(x) removeWords(x,stopwords("english")))
#remove some unintersting words
words_to_remove <- c("said","from","what","told","over","more","other","have","last","with","this","that","such","when","been","says","will","also","where","why","would","today")
dataset_corpus_all <- tm_map(dataset_corpus_all, removeWords, words_to_remove)
# compute term matrix & convert to matrix class --> you get a table summarizing the occurence of each word in each class.
document_tm <- TermDocumentMatrix(dataset_corpus_all)
document_tm_mat <- as.matrix(document_tm)
colnames(document_tm_mat) <- unique_labels
document_tm_clean <- removeSparseTerms(document_tm, 0.8)
document_tm_clean_mat <- as.matrix(document_tm_clean)
colnames(document_tm_clean_mat) <- unique_labels
# remove words in term matrix with length < 4
index <- as.logical(sapply(rownames(document_tm_clean_mat), function(x) (nchar(x)>3) ))
document_tm_clean_mat_s <- document_tm_clean_mat[index,]
# Have a look to the matrix you are going to use for wordcloud !
head(document_tm_clean_mat_s)
# Graph 1 : first top 500 discriminant words
png("#102_1_comparison_cloud_top_500_words.png", width = 480, height = 480)
comparison.cloud(document_tm_clean_mat_s, max.words=500, random.order=FALSE,c(4,0.4), title.size=1.4)
dev.off()
# Graph 2 : first top 2000 discriminant words
png("#102_1_comparison_cloud_top_2000_words.png", width = 480, height = 480)
comparison.cloud(document_tm_clean_mat_s,max.words=2000,random.order=FALSE,c(4,0.4), title.size=1.4)
dev.off()
# Graph 3: commonality word cloud : first top 2000 common words across classes
png("#103_commonality_wordcloud.png", width = 480, height = 480)
commonality.cloud(document_tm_clean_mat_s, max.words=2000, random.order=FALSE)
dev.off()
library(reshape)
library(tm)
library(wordcloud)
# -- STEP 1 : GET THE DATA
# A dataset with 5485 lines, each line has several words.
dataset=read.delim("https://raw.githubusercontent.com/TATABOX42/text-mining-in-r/master/dataset.txt", header=FALSE)
# The labels of each line of the dataset file
dataset_labels <- read.delim("https://raw.githubusercontent.com/TATABOX42/text-mining-in-r/master/labels.txt",header=FALSE)
dataset_labels <- dataset_labels[,1]
dataset_labels_p <- paste("class",dataset_labels,sep="_")
unique_labels <- unique(dataset_labels_p)
# merge documents that match certain class into a list object
dataset_s <- sapply(unique_labels,function(label) list( dataset[dataset_labels_p %in% label,1] ) )
# -- STEP2 : COMPUTE DOCUMENT CORPUS TO MAKE TEXT MINING
# convert each list content into a corpus
dataset_corpus <- lapply(dataset_s, function(x) Corpus(VectorSource( toString(x) )))
# merge all documents into one single corpus
dataset_corpus_all <- dataset_corpus[[1]]
for (i in 2:length(unique_labels)) { dataset_corpus_all <- c(dataset_corpus_all,dataset_corpus[[i]]) }
# remove punctuation, numbers and stopwords
dataset_corpus_all <- tm_map(dataset_corpus_all, removePunctuation)
str(dataset_corpus_all)
# remove punctuation, numbers and stopwords
dataset_corpus_all <- tm_map(dataset_corpus_all, removePunctuation)
View(dataset)
dataset
View(dataset_corpus)
View(dataset_corpus)
View(dataset_corpus_all)
esp <- c(3.6, 28.8, 57.6, 16.8, 134.4, 268.8, 19.6, 156.8, 313.6)
obs <- c(3, 27, 61, 18, 123, 281, 18, 152, 317)
((obs - esp)^2)/2
sum(((obs - esp)^2)/2)
library(ggplot2)
(obs - esp)^2 %>% /2 %>% sum()
(obs - esp)^2
((obs - esp)^2)/esp
lis <- ((obs - esp)^2)/esp
sum(lis)
datos=matrix(c(32,14,6,12,22,9),ncol=2)
View(datos)
View(datos)
View(Dfpoiss)
##library_______________________________________________________________________
library(tidyverse)
library(ggplot2)
library(viridis)
library(dplyr)
library(gridExtra)
library(viridis)
setwd("/home/usuario/Data_Rstudio/tesina_g/tablas/athila_candidate_clade/")
tab_clade_at <- read.csv("Id_new.clade.csv",
sep = "\t",
stringsAsFactors = TRUE)
tab_id_db_gy <- read.csv("Id_length_RT_gy_total.csv",
sep = "\t",
stringsAsFactors = TRUE)
##we will need mean and standard deviation of the transposons
gy_db_Length <- read.csv("/home/usuario/Data_Rstudio/tesina_g/tablas/dataBase_statics/Length_LTR_genome_gy_db.csv",
sep = ",",
stringsAsFactors = T)
summary(tab_clade_at)
str(tab_clade_at)
summary(tab_id_db_gy)
str(tab_id_db_gy)
summary(gy_db_Length)
str(gy_db_Length)
tab_clade_at
for(i in duplicated(tab_clade_at)){
if(i != FALSE){
thereAre  <-("Duplicate")
} else {
thereArenT   <- ("Any duplicate")
}
}
duplicated(tab_clade_at)
for(i in duplicated(tab_clade_at)){
if(i != FALSE){
return('Hay duplicacion')
} else {
return('NO')
}
}
for(i in duplicated(tab_clade_at)){
if(i != FALSE){
print('Hay duplicacion')
} else {
print('NO')
}
}
for(i in duplicated(tab_clade_at)){
if(i != FALSE){
return(i)
} else {
return(i)
}
}
for(i in duplicated(tab_clade_at)){
if(i != FALSE){
print(i)
} else {
print(i)
}
}
for(i in duplicated(tab_clade_at)){
if(i != FALSE){
print(i)
} else {
print('NO')
}
}
for(i in duplicated(tab_id_db_gy)){
if(i != FALSE){
print(i)
} else {
print('NO')
}
}
for(i in duplicated(tab_id_db_gy)){
if(i != FALSE){
print(i)
} else {
print('NO')
} if (i == TRUE){
remove(i)
}
}
for(i in duplicated(tab_id_db_gy)){
if(i != FALSE){
print(i)
} else {
print('NO')
} if (i == TRUE){
remove(i)
} else {
print('CLEAN')
}
}
for(i in duplicated(tab_id_db_gy)){
for(i in duplicated(tab_id_db_gy)){
if(i != FALSE){
print(i)
} else {
print('NO')
}
}
for(i in duplicated(tab_id_db_gy)){
if(i != FALSE){
print(i)
} else {
print('NO')
}
}
for(i in duplicated(tab_clade_at)){
if(i != FALSE){
print(i)
} else {
print('NO')
}
}
for(i in duplicated(tab_id_db_gy)){
if(i != FALSE){
print(i)
} else {
print('NO')
}
}
summary(Id_length_clade)
str(Id_length_clade)
meanOfDb <- mean(gy_db_Length$G.length)
sdOfDb <- sd(gy_db_Length$G.length)
Id_length_clade <- merge(tab_clade_at, tab_id_db_gy, by = "ID")
summary(Id_length_clade)
str(Id_length_clade)
meanOfDb <- mean(gy_db_Length$G.length)
sdOfDb <- sd(gy_db_Length$G.length)
only_length <- Id_length_clade[,2:3]
Id_length_clade$Se <- ifelse(Id_length_clade$S > Id_length_clade$E, round(meanOfDb + sdOfDb), round(-meanOfDb-sdOfDb))
Id_length_clade$Es <- ifelse(Id_length_clade$E < Id_length_clade$S, round(-meanOfDb-sdOfDb), round(meanOfDb + sdOfDb))
Id_length_clade$S <- Id_length_clade$S + Id_length_clade$Se
Id_length_clade$E <- Id_length_clade$E + Id_length_clade$Es
Id_length_clade$S <- ifelse(Id_length_clade$S < 0 , Id_length_clade$S*0, Id_length_clade$S*1)
Id_length_clade$E <- ifelse(Id_length_clade$E < 0 , Id_length_clade$E*0, Id_length_clade$E*1)
Id_length_clade$ID <- paste0(rep(">",length(Id_length_clade$ID)), Id_length_clade$ID)
length(Id_length_clade$ID)
str(only_length)
(nth <- paste(1:12, c("st", "nd", "rd", rep("th", 9))))
nth
str(only_length)
Id_length_clade
Id_length_clade <- merge(tab_clade_at, tab_id_db_gy, by = "ID")
summary(Id_length_clade)
str(Id_length_clade)
meanOfDb <- mean(gy_db_Length$G.length)
sdOfDb <- sd(gy_db_Length$G.length)
only_length <- Id_length_clade[,2:3]
Id_length_clade$Se <- ifelse(Id_length_clade$S > Id_length_clade$E, round(meanOfDb + sdOfDb), round(-meanOfDb-sdOfDb))
Id_length_clade
Id_length_clade$Es <- ifelse(Id_length_clade$E < Id_length_clade$S, round(-meanOfDb-sdOfDb), round(meanOfDb + sdOfDb))
Id_length_clade
Id_length_clade$S <- Id_length_clade$S + Id_length_clade$Se
Id_length_clade
Id_length_clade$E <- Id_length_clade$E + Id_length_clade$Es
Id_length_clade
Id_length_clade$S <- ifelse(Id_length_clade$S < 0 , Id_length_clade$S*0, Id_length_clade$S*1)
Id_length_clade
Id_length_clade$E <- ifelse(Id_length_clade$E < 0 , Id_length_clade$E*0, Id_length_clade$E*1)
Id_length_clade
Id_length_clade$ID <- paste0(rep(">",length(Id_length_clade$ID)), Id_length_clade$ID)
Id_length_clade
length(Id_length_clade$ID)
str(only_length)
