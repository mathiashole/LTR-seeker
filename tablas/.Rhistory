y[ 2 <= y <= 5]
y[y <= 5][y >= 2]
y[y >= 2][y <= 5]
y[y >= 2][y <= 5]
y[y >= 2], [y <= 5]
y ([y >= 2] [y <= 5])
y [y >= 2, y <= 5]
y [y <= 5]
y [y >= 2]
y [y <= 5] [y >= 2]
y [y <= 5] & [y >= 2]
y [y <= 5][y >= 2]
m <- y [y <= 5][y >= 2]
m
sort(m)
sort(-m)
sort(m)
m*m
m% * %m
m%*%m
m%*%m
install.packages("combinat")
library(combinat)
library(combinat)
permn(100)
permn(2)
permn(9)
permn(3)
permn(2)
permn(10)
View(largo_ltr)
library(ggplot2)
p <- ggplot(mtcars, aes(x=wt, y=mpg, color=cyl, size=cyl))+
geom_point()+
theme(legend.position = "none", panel.background = element_rect(fill = "white", colour =  "grey50"))
library(ggExtra)
ggMarginal(p, type = "histogram", fill = "grey", xparams = list(bins= 30))
ggMarginal(p, type = "density", fill = "#69b3a2", , color="#e9ecef", alpha=0.8)
p <- ggplot(mtcars, aes(x=wt, y=mpg, color=cyl, size=cyl))+
geom_point()+
theme(legend.position = "none", panel.background = element_rect(fill = "white", colour =  "grey50"))+
geom_smooth(method = "lm")
ggMarginal(p, type = "density", fill = "#69b3a2", , color="#e9ecef", alpha=0.8)
n = seq(100,1000,100)
#Se define un vector en secuencia de 100 en 100 hasta 1000
sec1000en100 = seq(100,1000,100)
xn = rep(0,10)
x = rpois(n[i],16.5)
x = rpois(sec1000en100[i],16.5)
xn = rep(0,10)
sn = rep(0,10)
for(i in 1:10){
x = rpois(sec1000en100[i],16.5)
sn[i] = (sd(x)^2)
xn[i] = mean(x)
}
xn
hola=rep(0,10)
hola
poissLGN[i] = mean(randomPoiss)}
#Bucle for para aplicar Ley de los Grandes N de 100 en 100, hasta 1000
for(i in 1:10){
randomPoiss = rpois(sec1000en100[i],16.5)
poissLGN[i] = mean(randomPoiss)
}
#Bucle for para aplicar Ley de los Grandes N de 100 en 100, hasta 1000
for(i in 1:10){
randomPoiss = rpois(sec1000en100[i],16.5)
poissLGN[i] = mean(randomPoiss)
}
poissLGN
poissLGN
#Se creo vectores de repeticion para guarda los resultados del bucle for
poissLGN = rep(0,10)
#Bucle for para aplicar Ley de los Grandes N de 100 en 100, hasta 1000
for(i in 1:10){
randomPoiss = rpois(sec1000en100[i],16.5)
poissLGN[i] = mean(randomPoiss)
}
poissLGN
library(ggplot2)
gppoissLGN = ggplot(poissLGN, aes( y=poissLGN, color=cyl, size=cyl))+
geom_point()
gppoissLGN = ggplot(poissLGN, aes( y=poissLGN, color=cyl, size=cyl))+
geom_point()
#Datafarme
psslgn <- c(15.86000, 15.79500, 16.37333, 16.49750, 16.23800, 16.52000, 16.69571, 16.51000, 16.57444, 16.31300)
#Datafarme
poissXn <- c(15.86000, 15.79500, 16.37333, 16.49750, 16.23800, 16.52000, 16.69571, 16.51000, 16.57444, 16.31300)
NXntotal <- c(1, 2, 3, 4, 5, 6, 7, 8, 10)
Dfpoiss <- data.frame(poissXn = poissXn, NXntotal = NXntotal)
NXntotal <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
Dfpoiss <- data.frame(poissXn = poissXn, NXntotal = NXntotal)
Dfpoiss
gppoissLGN = ggplot(poissLGN, aes(x=NXntotal, y=poissXn, color=cyl, size=cyl))+
geom_point()
gppoissLGN = ggplot(Dfpoiss, aes(x=NXntotal, y=poissXn, color=cyl, size=cyl))+
geom_point()
gppoissLGN = ggplot(Dfpoiss, aes(x=NXntotal, y=poissXn, color=cyl, size=cyl))+
geom_point()+
theme(legend.position = "none", panel.background = element_rect(fill = "white", colour =  "grey50"))+
geom_smooth(method = "lm")
gppoissLGN
gppoissLGN = ggplot(Dfpoiss, aes(x=NXntotal, y=poissXn, color="black", size="black"))+
geom_point()+
theme(legend.position = "none", panel.background = element_rect(fill = "white", colour =  "grey50"))+
geom_smooth(method = "lm")
gppoissLGN
gppoissLGN = ggplot(Dfpoiss, aes(x=NXntotal, y=poissXn, color="black", size="black"))+
geom_point()+
theme(legend.position = "none", panel.background = element_rect(fill = "white", colour =  "grey50"))+
geom_smooth(method =)
gppoissLGN
gppoissLGN = ggplot(Dfpoiss, aes(x=NXntotal, y=poissXn, color="black", size="black"))+
geom_point()+
theme(legend.position = "none", panel.background = element_rect(fill = "white", colour =  "grey50"))+
geom_smooth(method = "lm")
gppoissLGN
library(ggExtra)
ggMarginal(p, type = "density", fill = "#69b3a2", , color="#e9ecef", alpha=0.8)
gppoissLGN = ggplot(Dfpoiss, aes(x=NXntotal, y=poissXn, color="black", size="black"))+
geom_point()+
theme(legend.position = "none", panel.background = element_rect(fill = "white", colour =  "grey50"))+
geom_smooth(method = "lm")
library(ggExtra)
ggMarginal(gppoissLGN, type = "density", fill = "#69b3a2", , color="#e9ecef", alpha=0.8))
ggMarginal(gppoissLGN, type = "density", fill = "#69b3a2", color="#e9ecef", alpha=0.8))
ggMarginal(gppoissLGN, type = "density", fill = "#69b3a2", color="#e9ecef", alpha=0.8)
mean_poiss <- mean(poissXn)
gppoissLGN = ggplot(Dfpoiss, aes(x=NXntotal, y=poissXn, color="black", size="black"))+
geom_point()+
theme(legend.position = "none", panel.background = element_rect(fill = "white", colour =  "grey50"))+
geom_hline(aes(yintercept = poissXn, colours = "#69b3a2"), mean_poiss)
library(ggExtra)
ggMarginal(gppoissLGN, type = "density", fill = "#69b3a2", color="#e9ecef", alpha=0.8)
gppoissLGN = ggplot(Dfpoiss, aes(x=NXntotal, y=poissXn, color="black", size="black"))+
geom_point()+
theme(legend.position = "none", panel.background = element_rect(fill = "white", colour =  "grey50"))+
geom_hline(mean_poiss)
library(ggExtra)
ggMarginal(gppoissLGN, type = "density", fill = "#69b3a2", color="#e9ecef", alpha=0.8)
gppoissLGN = ggplot(Dfpoiss, aes(x=NXntotal, y=poissXn, color="black", size="black"))+
geom_point()+
theme(legend.position = "none", panel.background = element_rect(fill = "white", colour =  "grey50"))+
library(ggExtra)
ggMarginal(gppoissLGN, type = "density", fill = "#69b3a2", color="#e9ecef", alpha=0.8)
gppoissLGN
ggMarginal(gppoissLGN, type = "density", fill = "#69b3a2", color="#e9ecef", alpha=0.8)
#Se define un vector en secuencia de 100 en 100 hasta 1000
sec1000en100 = seq(100,1000,100)
#Se creo vectores de repeticion para guarda los resultados del bucle for
poissLGN = rep(0,10)
#Bucle for para aplicar Ley de los Grandes N de 100 en 100, hasta 1000
for(i in 1:10){
randomPoiss = rpois(sec1000en100[i],16.5)
poissLGN[i] = mean(randomPoiss)
}
#Se crea un Datafarme para darle los datos a ggplot
poissXn <- c(15.86000, 15.79500, 16.37333, 16.49750, 16.23800, 16.52000, 16.69571, 16.51000, 16.57444, 16.31300)
NXntotal <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
Dfpoiss <- data.frame(poissXn = poissXn, NXntotal = NXntotal)
mean_poiss <- mean(poissXn)
library(ggplot2)
gppoissLGN = ggplot(Dfpoiss, aes(x=NXntotal, y=poissXn, color="black", size="black"))+
geom_point()+
theme(legend.position = "none", panel.background = element_rect(fill = "white", colour =  "grey50"))+
library(ggExtra)
ggMarginal(gppoissLGN, type = "density", fill = "#69b3a2", color="#e9ecef", alpha=0.8)
gppoissLGN = ggplot(Dfpoiss, aes(x=NXntotal, y=poissXn, color="black", size="black"))+
geom_point()+
theme(legend.position = "none", panel.background = element_rect(fill = "white", colour =  "grey50"))
library(ggExtra)
ggMarginal(gppoissLGN, type = "density", fill = "#69b3a2", color="#e9ecef", alpha=0.8)
gppoissLGN = ggplot(Dfpoiss, aes(x=NXntotal, y=poissXn, color="black", size="black"))+
geom_point()+
theme(legend.position = "none", panel.background = element_rect(fill = "white", colour =  "grey50"))+
geom_hline(yintercept = 16.5)
library(ggExtra)
ggMarginal(gppoissLGN, type = "density", fill = "#69b3a2", color="#e9ecef", alpha=0.8)
gppoissLGN = ggplot(Dfpoiss, aes(x=NXntotal, y=poissXn, color="black", size="black"))+
geom_point()+
theme(legend.position = "none", panel.background = element_rect(fill = "white", colour =  "grey50"))+
geom_hline(yintercept = 16.5, colour = "#69b3a2")
library(ggExtra)
ggMarginal(gppoissLGN, type = "density", fill = "#69b3a2", color="#e9ecef", alpha=0.8)
gppoissLGN = ggplot(Dfpoiss, aes(x=NXntotal, y=poissXn, color="black", size="black"))+
geom_point()+
theme(legend.position = "none", panel.background = element_rect(fill = "white", colour =  "grey50"))+
geom_hline(yintercept = 16.5, colour = "#69b3a2", size = 10)
library(ggExtra)
ggMarginal(gppoissLGN, type = "density", fill = "#69b3a2", color="#e9ecef", alpha=0.8)
gppoissLGN = ggplot(Dfpoiss, aes(x=NXntotal, y=poissXn, color="black", size="black"))+
geom_point()+
theme(legend.position = "none", panel.background = element_rect(fill = "white", colour =  "grey50"))+
geom_hline(yintercept = 16.5, colour = "#69b3a2", size = 3)
library(ggExtra)
ggMarginal(gppoissLGN, type = "density", fill = "#69b3a2", color="#e9ecef", alpha=0.8)
gppoissLGN = ggplot(Dfpoiss, aes(x=NXntotal, y=poissXn, color="black", size="black"))+
geom_point()+
theme(legend.position = "none", panel.background = element_rect(fill = "white", colour =  "grey50"))+
geom_hline(yintercept = 16.5, colour = "#69b3a2", size = 2)
library(ggExtra)
ggMarginal(gppoissLGN, type = "density", fill = "#69b3a2", color="#e9ecef", alpha=0.8)
gppoissLGN = ggplot(Dfpoiss, aes(x=NXntotal, y=poissXn, color="black", size="black"))+
geom_point()+
theme(legend.position = "none", panel.background = element_rect(fill = "white", colour =  "grey50"))+
geom_hline(yintercept = 16.5, colour = "#69b3a2", size = 1)
library(ggExtra)
ggMarginal(gppoissLGN, type = "density", fill = "#69b3a2", color="#e9ecef", alpha=0.8)
#Se define un vector en secuencia de 100 en 100 hasta 1000
sec1000en100 = seq(100,1000,100)
VarianzaPoiss = rep(0,10)
#Bucle for para aplicar Ley de los Grandes N y calcular Varianza
for(i in 1:10){
randomPoiss = rpois(sec1000en100[i],16.5)
VarianzaPoiss[i] = (sd(x)^2)
poissLGN[i] = mean(randomPoiss)
}
#Bucle for para aplicar Ley de los Grandes N y calcular Varianza
for(i in 1:10){
randomPoiss = rpois(sec1000en100[i],16.5)
VarianzaPoiss[i] = (sd(randomPoiss)^2)
poissLGN[i] = mean(randomPoiss)
}
VarianzaPoiss
#Se crea un Datafarme para darle los datos a ggplot de la Varianza
varianzaPss <- c(19.41051, 14.53266, 15.94759, 14.67466, 16.75253, 16.27222, 15.89483, 15.69960, 16.60458, 16.01401)
nVarianza <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
DfVarianzaPss <- data.frame(varianzaPss = varianzaPss, nVarianza = nVarianza)
library(ggplot2)
ggVarianzaPoiss = ggplot(DfVarianzaPss, aes(x=nVarianza, y=varianzaPss, color="black", size="black"))+
geom_point()+
theme(legend.position = "none", panel.background = element_rect(fill = "white", colour =  "grey50"))
library(ggExtra)
ggMarginal(, type = "density", fill = "#69b3a2", color="#e9ecef", alpha=0.8)
ggVarianzaPoiss
library(ggExtra)
ggMarginal(, type = "density", fill = "#69b3a2", color="#e9ecef", alpha=0.8)
ggMarginal(ggVarianzaPoiss, type = "density", fill = "#69b3a2", color="#e9ecef", alpha=0.8)
ggVarianzaPoiss = ggplot(DfVarianzaPss, aes(x=nVarianza, y=varianzaPss, color="black", size="black"))+
geom_point()+
theme(legend.position = "none", panel.background = element_rect(fill = "white", colour =  "grey50"))+
geom_hline(yintercept = 16.5, colour = "#69b3a2", size = 1)
ggMarginal(ggVarianzaPoiss, type = "density", fill = "#69b3a2", color="#e9ecef", alpha=0.8)
ggVarianzaPoiss = ggplot(DfVarianzaPss, aes(x=nVarianza, y=varianzaPss, color="black", size="black"))+
geom_point()+
theme(legend.position = "none", panel.background = element_rect(fill = "white", colour =  "grey50"))+
geom_hline(yintercept = 16.33, colour = "#69b3a2", size = 1)
library(ggExtra)
ggMarginal(ggVarianzaPoiss, type = "density", fill = "#69b3a2", color="#e9ecef", alpha=0.8)
ggVarianzaPoiss = ggplot(DfVarianzaPss, aes(x=nVarianza, y=varianzaPss, color="black", size="black"))+
geom_point()+
theme(legend.position = "none", panel.background = element_rect(fill = "white", colour =  "grey50"))+
geom_hline(yintercept = 16.5, colour = "#69b3a2", size = 1)
library(ggExtra)
ggMarginal(ggVarianzaPoiss, type = "density", fill = "#69b3a2", color="#e9ecef", alpha=0.8)
View(Dfpoiss)
View(Dfpoiss)
install.packages("BiocManager")
BiocManager::available()
BiocManager::install()
library(BiocManager)
clear
lss
les
less
library(BiocManager)
matrix(runif(25,1,100), ncol = 5)
matrix(runif(20,1,100), ncol = 5)
matrix(runif(25,1,100), nrow = 5)
matrix(runif(25,1,100))
runif(25,1,100)
x[5,]
x <-runif(25,1,100)
x[5,]
x[,5]
x[5]
x[length(5)]
View(DfVarianzaPss)
DfVarianzaPss[1:2]
DfVarianzaPss[,c(1,2)]
DfVarianzaPss[,1:2]
DfVarianzaPss$peso$altura
install.packages("BiocManager")
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("Biobase")
y
ls
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install(version = "3.14")
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install(version = "3.14")
BiocManager::install("Biostrings")
library(Biobase)
BiocManager::install("Biostrings")
Biostrings
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("Biostrings")
library("Biostrings")
install.packages("wordcloud2")
inscripciones <- c(330, 589, 967, 750, 2366, 634)
facultades <- c("Agronomía","Veterinaria","Arquitectura, Diseño y Urbanismo","Ciencias ","Ingeniería","Química")
inscripciones <- c(330, 589, 967, 750, 2366, 634)
dataf <- data.frame(facultades, inscripciones)
library(wordcloud2)
wordcloud2(data = dataf, size=1.6)
wordcloud2(data = dataf)
facultades <- c("Agronomía","Veterinaria","Arquitectura","Ciencias ","Ingeniería","Química")
inscripciones <- c(330, 589, 967, 750, 2366, 634)
dataf
wordcloud2(data = dataf)
facultades <- c("Agronomía","Veterinaria","Arquitectura","Ciencias ","Ingenieria","Quimica")
inscripciones <- c(330, 589, 967, 750, 2366, 634)
dataf <- data.frame(facultades, inscripciones)
library(wordcloud2)
wordcloud2(data = dataf)
wordcloud2(data = dataf, size=1.6, color='random-dark')
wordcloud2(data = dataf, size=1.6, color='random-light', backgroundColor="black")
wordcloud2(data = dataf, size=5, color='random-light', backgroundColor="black")
wordcloud2(data = dataf, size=1, color='random-light', backgroundColor="black")
wordcloud2(data = dataf, size=0.3, color='random-light', backgroundColor="black")
wordcloud2(data = dataf, size=0.4, color='random-light', backgroundColor="black")
wordcloud2(data = dataf, size=0.9, color='random-light', backgroundColor="black")
wordcloud2(data = dataf, size=0.8, color='random-light', backgroundColor="black")
wordcloud2(data = dataf, size=0.7, color='random-light', backgroundColor="black")
wordcloud2(data = dataf, size=0.6, color='random-light', backgroundColor="black")
wordcloud2(data = dataf, size=0.5, color='random-light', backgroundColor="black")
wordcloud2(data = dataf, size=0.5, color='random-light', backgroundColor="black")
wordcloud2(data = dataf, size=0.5, color='random-light', backgroundColor="black")
wordcloud2(data = dataf, size=0.5, color='random-light', backgroundColor="black")
wordcloud2(data = dataf, size=0.5, color='random-light', backgroundColor="black")
wordcloud2(data = dataf, size=0.5, color='random-light', backgroundColor="black")
wordcloud2(data = dataf, size=0.5, color='random-light', backgroundColor="black")
wordcloud2(data = dataf, size=0.5, color='random-light', backgroundColor="black")
wordcloud2(data = dataf, size=0.5, color='random-light', backgroundColor="black")
facultades <- c("Agronomía","Veterinaria","Arquitectura","Ciencias ","Ingenieria","Quimica")
inscripciones <- c(330, 589, 967, 750, 2366, 634)
dataf <- data.frame(facultades, inscripciones)
library(wordcloud2)
wordcloud2(data = dataf, size=0.5, color='random-light', backgroundColor="black")
wordcloud2(data = dataf, size=0.5, color='random-light', backgroundColor="black")
facultades <- c("Agronomía","Veterinaria","Arquitectura","Ciencias ","Ingenieria","Quimica")
inscripciones <- c(330, 589, 967, 750, 2366, 634)
dataf <- data.frame(facultades, inscripciones)
library(wordcloud2)
wordcloud2(data = dataf, size=0.5, color='random-light', backgroundColor="black")
install.packages("reshape")
install.packages("tm")
# -- STEP 1 : GET THE DATA
# A dataset with 5485 lines, each line has several words.
dataset=read.delim("https://raw.githubusercontent.com/TATABOX42/text-mining-in-r/master/dataset.txt", header=FALSE)
View(dataset)
# The labels of each line of the dataset file
dataset_labels <- read.delim("https://raw.githubusercontent.com/TATABOX42/text-mining-in-r/master/labels.txt",header=FALSE)
View(dataset_labels)
dataset_labels <- dataset_labels[,1]
dataset_labels <- dataset_labels[,1]
# The labels of each line of the dataset file
dataset_labels <- read.delim("https://raw.githubusercontent.com/TATABOX42/text-mining-in-r/master/labels.txt",header=FALSE)
dataset_labels <- dataset_labels[,1]
dataset_labels_p <- paste("class",dataset_labels,sep="_")
View(dataset)
unique_labels <- unique(dataset_labels_p)
# merge documents that match certain class into a list object
dataset_s <- sapply(unique_labels,function(label) list( dataset[dataset_labels_p %in% label,1] ) )
View(dataset_s)
# -- STEP2 : COMPUTE DOCUMENT CORPUS TO MAKE TEXT MINING
# convert each list content into a corpus
dataset_corpus <- lapply(dataset_s, function(x) Corpus(VectorSource( toString(x) )))
# merge documents that match certain class into a list object
dataset_s <- sapply(unique_labels,function(label) list( dataset[dataset_labels_p %in% label,1] ) )
# -- STEP2 : COMPUTE DOCUMENT CORPUS TO MAKE TEXT MINING
# convert each list content into a corpus
dataset_corpus <- lapply(dataset_s, function(x) Corpus(VectorSource( toString(x) )))
# merge all documents into one single corpus
dataset_corpus_all <- dataset_corpus[[1]]
for (i in 2:length(unique_labels)) { dataset_corpus_all <- c(dataset_corpus_all,dataset_corpus[[i]]) }
# remove punctuation, numbers and stopwords
dataset_corpus_all <- tm_map(dataset_corpus_all, removePunctuation)
dataset_corpus_all <- tm_map(dataset_corpus_all, removeNumbers)
dataset_corpus_all <- tm_map(dataset_corpus_all, function(x) removeWords(x,stopwords("english")))
#remove some unintersting words
words_to_remove <- c("said","from","what","told","over","more","other","have","last","with","this","that","such","when","been","says","will","also","where","why","would","today")
dataset_corpus_all <- tm_map(dataset_corpus_all, removeWords, words_to_remove)
# compute term matrix & convert to matrix class --> you get a table summarizing the occurence of each word in each class.
document_tm <- TermDocumentMatrix(dataset_corpus_all)
document_tm_mat <- as.matrix(document_tm)
colnames(document_tm_mat) <- unique_labels
document_tm_clean <- removeSparseTerms(document_tm, 0.8)
document_tm_clean_mat <- as.matrix(document_tm_clean)
colnames(document_tm_clean_mat) <- unique_labels
# remove words in term matrix with length < 4
index <- as.logical(sapply(rownames(document_tm_clean_mat), function(x) (nchar(x)>3) ))
document_tm_clean_mat_s <- document_tm_clean_mat[index,]
# Have a look to the matrix you are going to use for wordcloud !
head(document_tm_clean_mat_s)
# merge all documents into one single corpus
dataset_corpus_all <- dataset_corpus[[1]]
library(reshape)
library(tm)
library(wordcloud)
# -- STEP 1 : GET THE DATA
# A dataset with 5485 lines, each line has several words.
dataset=read.delim("https://raw.githubusercontent.com/TATABOX42/text-mining-in-r/master/dataset.txt", header=FALSE)
# The labels of each line of the dataset file
dataset_labels <- read.delim("https://raw.githubusercontent.com/TATABOX42/text-mining-in-r/master/labels.txt",header=FALSE)
dataset_labels <- dataset_labels[,1]
dataset_labels_p <- paste("class",dataset_labels,sep="_")
unique_labels <- unique(dataset_labels_p)
# merge documents that match certain class into a list object
dataset_s <- sapply(unique_labels,function(label) list( dataset[dataset_labels_p %in% label,1] ) )
# -- STEP2 : COMPUTE DOCUMENT CORPUS TO MAKE TEXT MINING
# convert each list content into a corpus
dataset_corpus <- lapply(dataset_s, function(x) Corpus(VectorSource( toString(x) )))
# merge all documents into one single corpus
dataset_corpus_all <- dataset_corpus[[1]]
for (i in 2:length(unique_labels)) { dataset_corpus_all <- c(dataset_corpus_all,dataset_corpus[[i]]) }
# remove punctuation, numbers and stopwords
dataset_corpus_all <- tm_map(dataset_corpus_all, removePunctuation)
# remove punctuation, numbers and stopwords
dataset_corpus_all <- tm_map(dataset_corpus_all, removePunctuation)
dataset_corpus_all <- tm_map(dataset_corpus_all, removeNumbers)
dataset_corpus_all <- tm_map(dataset_corpus_all, function(x) removeWords(x,stopwords("english")))
#remove some unintersting words
words_to_remove <- c("said","from","what","told","over","more","other","have","last","with","this","that","such","when","been","says","will","also","where","why","would","today")
dataset_corpus_all <- tm_map(dataset_corpus_all, removeWords, words_to_remove)
# compute term matrix & convert to matrix class --> you get a table summarizing the occurence of each word in each class.
document_tm <- TermDocumentMatrix(dataset_corpus_all)
document_tm_mat <- as.matrix(document_tm)
colnames(document_tm_mat) <- unique_labels
document_tm_clean <- removeSparseTerms(document_tm, 0.8)
document_tm_clean_mat <- as.matrix(document_tm_clean)
colnames(document_tm_clean_mat) <- unique_labels
# remove words in term matrix with length < 4
index <- as.logical(sapply(rownames(document_tm_clean_mat), function(x) (nchar(x)>3) ))
document_tm_clean_mat_s <- document_tm_clean_mat[index,]
# Have a look to the matrix you are going to use for wordcloud !
head(document_tm_clean_mat_s)
# Graph 1 : first top 500 discriminant words
png("#102_1_comparison_cloud_top_500_words.png", width = 480, height = 480)
comparison.cloud(document_tm_clean_mat_s, max.words=500, random.order=FALSE,c(4,0.4), title.size=1.4)
dev.off()
# Graph 2 : first top 2000 discriminant words
png("#102_1_comparison_cloud_top_2000_words.png", width = 480, height = 480)
comparison.cloud(document_tm_clean_mat_s,max.words=2000,random.order=FALSE,c(4,0.4), title.size=1.4)
dev.off()
# Graph 3: commonality word cloud : first top 2000 common words across classes
png("#103_commonality_wordcloud.png", width = 480, height = 480)
commonality.cloud(document_tm_clean_mat_s, max.words=2000, random.order=FALSE)
dev.off()
library(reshape)
library(tm)
library(wordcloud)
# -- STEP 1 : GET THE DATA
# A dataset with 5485 lines, each line has several words.
dataset=read.delim("https://raw.githubusercontent.com/TATABOX42/text-mining-in-r/master/dataset.txt", header=FALSE)
# The labels of each line of the dataset file
dataset_labels <- read.delim("https://raw.githubusercontent.com/TATABOX42/text-mining-in-r/master/labels.txt",header=FALSE)
dataset_labels <- dataset_labels[,1]
dataset_labels_p <- paste("class",dataset_labels,sep="_")
unique_labels <- unique(dataset_labels_p)
# merge documents that match certain class into a list object
dataset_s <- sapply(unique_labels,function(label) list( dataset[dataset_labels_p %in% label,1] ) )
# -- STEP2 : COMPUTE DOCUMENT CORPUS TO MAKE TEXT MINING
# convert each list content into a corpus
dataset_corpus <- lapply(dataset_s, function(x) Corpus(VectorSource( toString(x) )))
# merge all documents into one single corpus
dataset_corpus_all <- dataset_corpus[[1]]
for (i in 2:length(unique_labels)) { dataset_corpus_all <- c(dataset_corpus_all,dataset_corpus[[i]]) }
# remove punctuation, numbers and stopwords
dataset_corpus_all <- tm_map(dataset_corpus_all, removePunctuation)
str(dataset_corpus_all)
# remove punctuation, numbers and stopwords
dataset_corpus_all <- tm_map(dataset_corpus_all, removePunctuation)
View(dataset)
dataset
View(dataset_corpus)
View(dataset_corpus)
View(dataset_corpus_all)
esp <- c(3.6, 28.8, 57.6, 16.8, 134.4, 268.8, 19.6, 156.8, 313.6)
obs <- c(3, 27, 61, 18, 123, 281, 18, 152, 317)
((obs - esp)^2)/2
sum(((obs - esp)^2)/2)
library(ggplot2)
(obs - esp)^2 %>% /2 %>% sum()
(obs - esp)^2
((obs - esp)^2)/esp
lis <- ((obs - esp)^2)/esp
sum(lis)
datos=matrix(c(32,14,6,12,22,9),ncol=2)
View(datos)
View(datos)
View(Dfpoiss)
##Librerias a usar______________________________________________________________
library(tidyverse)
library(ggplot2)
library(viridis)
library(dplyr)
library(gridExtra)
library(RColorBrewer)
##Directorio y base de datos____________________________________________________
setwd("/home/usuario/Data_Rstudio/tesina_g/tablas/")
lathi <- read.csv("largo_athila_DB.csv", sep = ";", stringsAsFactors = TRUE)
str(lathi)
summary(lathi)
row.names(lathi) <- lathi$nombre
row.names(lathi) <- LETTERS[1:4]
lathi
